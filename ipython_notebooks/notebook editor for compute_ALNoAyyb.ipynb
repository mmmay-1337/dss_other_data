{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-py_38_geo-cpu-xl-2-cpu-16gb-ram",
      "display_name": "Python in CPU-XL-2-cpu-16Gb-Ram (env py_38_geo)",
      "language": "python"
    },
    "associatedRecipe": "compute_ALNoAyyb",
    "creator": "may.phang@dataiku.com",
    "createdOn": 1697090031063,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.8.17",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "may.phang@dataiku.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# import the netcdf4 module\nimport netCDF4 as nc\nimport io\nimport shutil"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nmain_folder \u003d dataiku.Folder(\"q60yhFTA\")\nmain_folder_info \u003d main_folder.get_info()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_to_download \u003d main_folder.list_paths_in_partition()[0]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_to_download"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly download the dataset, as the dataset was in the s3 folder"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tempfile\n\n# with io.BytesIO() as stream:\n#     with main_folder.get_download_stream(\u00270_aus-9km_20230510_cb05_glot_0.090dg_f10_2d_cf.nc\u0027) as folder_stream:\n#         shutil.copyfileobj(folder_stream, stream)\n#     stream.seek(0)\n#     data \u003d nc.Dataset(stream)\n\n# Download the model to a temporary file, then load it\nwith tempfile.TemporaryFile() as temp_file:\n    with main_folder.get_download_stream(\"/0_aus-9km_20230510_cb05_glot_0.090dg_f10_2d_cf.nc\") as folder_stream:\n        shutil.copyfileobj(folder_stream, temp_file)\n#     temp_file # .seek(0)\n    data \u003d nc.Dataset(temp_file)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!ls"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset \u003d nc.Dataset(netcdf_fsf_info[\u0027path\u0027] + file_to_download)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\ndata_processed \u003d dataiku.Folder(\"ALNoAyyb\")\ndata_processed_info \u003d data_processed.get_info()"
      ],
      "outputs": []
    }
  ]
}